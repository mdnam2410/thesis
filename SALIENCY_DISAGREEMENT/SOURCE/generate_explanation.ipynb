{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ7VowTTEBks"
   },
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:25.271193Z",
     "iopub.status.busy": "2023-06-26T09:02:25.269973Z",
     "iopub.status.idle": "2023-06-26T09:02:28.198761Z",
     "shell.execute_reply": "2023-06-26T09:02:28.197556Z",
     "shell.execute_reply.started": "2023-06-26T09:02:25.271155Z"
    },
    "id": "erPY0MqyEU_X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for inference\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import (Saliency, GradientShap, DeepLift, IntegratedGradients, NoiseTunnel, GuidedGradCam, GuidedBackprop, Occlusion, LRP, visualization as viz, KernelShap, FeaturePermutation, ShapleyValueSampling)\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import warnings\n",
    "\n",
    "from pneumothorax_image_dataset import PneumothoraxImageDataset\n",
    "import utils\n",
    "\n",
    "# Matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Devices\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "cpu = torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:28.213998Z",
     "iopub.status.busy": "2023-06-26T09:02:28.213338Z",
     "iopub.status.idle": "2023-06-26T09:02:28.222224Z",
     "shell.execute_reply": "2023-06-26T09:02:28.220706Z",
     "shell.execute_reply.started": "2023-06-26T09:02:28.213961Z"
    },
    "id": "vLfyNmtEM1SB"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIEBF6WUzAQA"
   },
   "source": [
    "# Setup datasets and configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: pneumothorax-chest-xray-dataset/siim-acr-pneumothorax\n",
      "Checkpoint path: pretrained_weights/\n"
     ]
    }
   ],
   "source": [
    "# Select environment\n",
    "DATASET_PATH, CHECKPOINT_PATH = utils.get_path('local')\n",
    "\n",
    "print(f'Dataset path: {DATASET_PATH}')\n",
    "print(f'Checkpoint path: {CHECKPOINT_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:28.258156Z",
     "iopub.status.busy": "2023-06-26T09:02:28.257438Z",
     "iopub.status.idle": "2023-06-26T09:02:28.267412Z",
     "shell.execute_reply": "2023-06-26T09:02:28.266528Z",
     "shell.execute_reply.started": "2023-06-26T09:02:28.258124Z"
    }
   },
   "outputs": [],
   "source": [
    "RUN_ON_TEST_SET_SAMPLE = True\n",
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:28.310307Z",
     "iopub.status.busy": "2023-06-26T09:02:28.309457Z",
     "iopub.status.idle": "2023-06-26T09:02:28.363985Z",
     "shell.execute_reply": "2023-06-26T09:02:28.363140Z",
     "shell.execute_reply.started": "2023-06-26T09:02:28.310275Z"
    },
    "id": "8G-yx78yQsMn"
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(os.path.join(DATASET_PATH, 'stage_1_test_images.csv'))\n",
    "test_data['images'] = test_data['new_filename'].apply(lambda x: os.path.join(DATASET_PATH, 'png_images', x))\n",
    "test_data['masks'] = test_data['new_filename'].apply(lambda x: os.path.join(DATASET_PATH, 'png_masks', x))\n",
    "\n",
    "filenames = test_data['new_filename'].tolist()\n",
    "images = test_data['images'].tolist()\n",
    "masks = test_data['masks'].tolist()\n",
    "targets = test_data['has_pneumo'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:28.371932Z",
     "iopub.status.busy": "2023-06-26T09:02:28.368894Z",
     "iopub.status.idle": "2023-06-26T09:02:28.379636Z",
     "shell.execute_reply": "2023-06-26T09:02:28.378424Z",
     "shell.execute_reply.started": "2023-06-26T09:02:28.371899Z"
    },
    "id": "vbo2-sZMQ1iU"
   },
   "outputs": [],
   "source": [
    "dataset = PneumothoraxImageDataset(filenames, images, targets, masks, utils.transform, utils.mask_transform)\n",
    "ds_loader = torch.utils.data.DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03NSEm1hf5Yk"
   },
   "source": [
    "## Setup Blackbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:28.386734Z",
     "iopub.status.busy": "2023-06-26T09:02:28.384943Z",
     "iopub.status.idle": "2023-06-26T09:02:33.058358Z",
     "shell.execute_reply": "2023-06-26T09:02:33.057345Z",
     "shell.execute_reply.started": "2023-06-26T09:02:28.386701Z"
    }
   },
   "outputs": [],
   "source": [
    "# ResNet\n",
    "resnet_cp = torch.load(f'{CHECKPOINT_PATH}/resnet_cp.pth', map_location=device)\n",
    "blackbox_resnet = models.resnet101()\n",
    "blackbox_resnet.load_state_dict(resnet_cp)\n",
    "blackbox_resnet = torch.nn.DataParallel(blackbox_resnet)\n",
    "blackbox_resnet = blackbox_resnet.eval().to(device)\n",
    "\n",
    "# InceptionV3\n",
    "checkpoint = torch.load(f'{CHECKPOINT_PATH}/inception_cp.pth', map_location=device)\n",
    "blackbox_inception = models.inception_v3()\n",
    "blackbox_inception.load_state_dict(checkpoint)\n",
    "blackbox_inception = torch.nn.DataParallel(blackbox_inception)\n",
    "blackbox_inception = blackbox_inception.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:33.060457Z",
     "iopub.status.busy": "2023-06-26T09:02:33.060063Z",
     "iopub.status.idle": "2023-06-26T09:02:33.067129Z",
     "shell.execute_reply": "2023-06-26T09:02:33.066208Z",
     "shell.execute_reply.started": "2023-06-26T09:02:33.060423Z"
    }
   },
   "outputs": [],
   "source": [
    "blackbox_configs = {\n",
    "    'ResNet': {\n",
    "        'module': blackbox_resnet,\n",
    "        'layer_name_for_guided_gc': 'layer4'\n",
    "    },\n",
    "    'InceptionV3': {\n",
    "        'module': blackbox_inception,\n",
    "        'layer_name_for_guided_gc': 'Mixed_7c'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZudcBlGD0so"
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:33.106294Z",
     "iopub.status.busy": "2023-06-26T09:02:33.105857Z",
     "iopub.status.idle": "2023-06-26T09:02:33.115139Z",
     "shell.execute_reply": "2023-06-26T09:02:33.114237Z",
     "shell.execute_reply.started": "2023-06-26T09:02:33.106261Z"
    },
    "id": "VUwIbTzPEA4y"
   },
   "outputs": [],
   "source": [
    "def get_explanation(xai_config, batch, targets):\n",
    "    \"\"\"Return the explanation of an XAI model for an input batch\n",
    "    \"\"\"\n",
    "    xai_model = xai_config['method']\n",
    "    options = xai_config['options']\n",
    "    attribution = xai_model.attribute(batch, target=targets, **options)\n",
    "    return attribution.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:33.117172Z",
     "iopub.status.busy": "2023-06-26T09:02:33.116444Z",
     "iopub.status.idle": "2023-06-26T09:02:33.126994Z",
     "shell.execute_reply": "2023-06-26T09:02:33.126391Z",
     "shell.execute_reply.started": "2023-06-26T09:02:33.117140Z"
    },
    "id": "PIGlN7X9H5Aw"
   },
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    t = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:33.129775Z",
     "iopub.status.busy": "2023-06-26T09:02:33.128397Z",
     "iopub.status.idle": "2023-06-26T09:02:33.136879Z",
     "shell.execute_reply": "2023-06-26T09:02:33.135726Z",
     "shell.execute_reply.started": "2023-06-26T09:02:33.129736Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_sum_to_one(x):\n",
    "    norm = normalize(x)\n",
    "    return norm / norm.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:33.138951Z",
     "iopub.status.busy": "2023-06-26T09:02:33.138318Z",
     "iopub.status.idle": "2023-06-26T09:02:33.146551Z",
     "shell.execute_reply": "2023-06-26T09:02:33.145345Z",
     "shell.execute_reply.started": "2023-06-26T09:02:33.138919Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_mean_disagreement(exp1, exp2, metric, **options):\n",
    "    metrics = []\n",
    "    for e1, e2 in zip(exp1, exp2):\n",
    "        metrics.append(metric(e1, e2, **options))\n",
    "    return np.array(metrics).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalarOutputWrapper(torch.nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super().__init__()\n",
    "        self.m = module\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.m(x)\n",
    "#         _, res = torch.topk(output, 1, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for generating explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:42.567544Z",
     "iopub.status.busy": "2023-06-26T09:02:42.567119Z",
     "iopub.status.idle": "2023-06-26T09:02:42.576256Z",
     "shell.execute_reply": "2023-06-26T09:02:42.574944Z",
     "shell.execute_reply.started": "2023-06-26T09:02:42.567479Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_explanations(xai_methods_dict, methods, ds_loader, indices, gpu_device):\n",
    "    explanations = {}\n",
    "    indices = indices.to(gpu_device)\n",
    "    \n",
    "    for method in methods:\n",
    "        explanations[method] = []\n",
    "\n",
    "    for method in methods:\n",
    "        print(f'Getting explanations of {method}...')\n",
    "        for i, data in enumerate(ds_loader):\n",
    "            batch = data[1]\n",
    "            batch_size = batch.shape[0]\n",
    "            if method in xai_methods_dict:\n",
    "                explanation = get_explanation(xai_methods_dict[method], batch.to(gpu_device), indices[i * batch_size:(i + 1) * batch_size])\n",
    "                explanation = explanation.cpu().detach()\n",
    "                explanations[method].append(explanation)\n",
    "            else:\n",
    "                explanations[method].append(torch.empty((1, *utils.INPUT_SIZE)).fill_(np.nan))\n",
    "    \n",
    "    return explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define starting baseline for GradientShap and Integrated Gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-26T09:02:42.578435Z",
     "iopub.status.busy": "2023-06-26T09:02:42.578071Z",
     "iopub.status.idle": "2023-06-26T09:02:42.594661Z",
     "shell.execute_reply": "2023-06-26T09:02:42.593547Z",
     "shell.execute_reply.started": "2023-06-26T09:02:42.578402Z"
    },
    "id": "hQ8hQhIoOwGo",
    "outputId": "bc981983-0b8f-45f6-c1c7-8e5b098d33a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_img_dist = torch.rand((1, 3, *utils.INPUT_SIZE)).to(device)\n",
    "rand_img_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xai_configs(blackbox_configs, blackbox_name):\n",
    "    blackbox_selected = blackbox_name\n",
    "    blackbox = blackbox_configs[blackbox_selected]['module']\n",
    "    layer = getattr(blackbox.module, blackbox_configs[blackbox_selected]['layer_name_for_guided_gc'])\n",
    "    \n",
    "    # Initialize attribution methods\n",
    "    sl = Saliency(blackbox)\n",
    "    guided_gc = GuidedGradCam(blackbox, layer)\n",
    "    gbp = GuidedBackprop(blackbox)\n",
    "    lrp = LRP(blackbox)\n",
    "    dl = DeepLift(ScalarOutputWrapper(blackbox))\n",
    "    gs = GradientShap(blackbox)\n",
    "    ig = IntegratedGradients(blackbox)\n",
    "    occlusion = Occlusion(blackbox)\n",
    "    \n",
    "    # Define configurations\n",
    "    xai_methods = {\n",
    "      \"Saliency\": { \"method\": sl , \"options\": {}},\n",
    "      \"GuidedGradCam\": { \"method\": guided_gc, \"options\": {'interpolate_mode': 'area'}},\n",
    "      \"GuidedBackprop\": { \"method\": gbp, \"options\": {}},\n",
    "      \"LRP\": { \"method\": lrp, \"options\": {}},\n",
    "      \"GradientShap\": { \"method\": gs, \"options\": { 'n_samples': 16, 'stdevs': 0.0001, 'baselines': rand_img_dist }},\n",
    "      \"IntegratedGradients\": { \"method\": ig, \"options\": { 'n_steps' : 100, 'internal_batch_size': 1 }, 'baselines': rand_img_dist },\n",
    "      \"Occlusion\": { \"method\": occlusion, \"options\": { 'sliding_window_shapes': (3,8, 8), 'strides': (3, 4, 4)}},\n",
    "    }\n",
    "    \n",
    "    if blackbox_name != 'ResNet':\n",
    "        xai_methods[\"DeepLift\"] = { \"method\": dl, \"options\": {}}\n",
    "    \n",
    "    return xai_methods, blackbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(blackbox_configs, blackbox_name, loader):\n",
    "    # Get configurations\n",
    "    xai_methods, blackbox = get_xai_configs(blackbox_configs, blackbox_name)\n",
    "    \n",
    "    # Evaluation\n",
    "    files = []\n",
    "    indices = []\n",
    "    for data in loader:\n",
    "        f, x, m, y = data\n",
    "        output = torch.nn.functional.softmax(blackbox(x.to(device)), dim=1)\n",
    "        _, index = torch.topk(output, k=1, dim=1)\n",
    "        indices.append(index.flatten())\n",
    "        files.extend(list(f))\n",
    "    indices = torch.concat(indices)\n",
    "    \n",
    "    \n",
    "    # Get gradient-based explanations\n",
    "    gradient_methods = ['Saliency', 'GuidedGradCam', 'GuidedBackprop', 'LRP', 'IntegratedGradients', 'GradientShap', 'DeepLift']\n",
    "    gradient_explanations = get_explanations(xai_methods, gradient_methods, loader, indices, device)\n",
    "    \n",
    "    # Get perturbation-based explanations\n",
    "    perturbation_methods = ['Occlusion']\n",
    "    perturbation_explanations = get_explanations(xai_methods, perturbation_methods, loader, indices, device)\n",
    "    \n",
    "    # Combine\n",
    "    explanations = {**gradient_explanations, **perturbation_explanations}\n",
    "    methods = gradient_methods + perturbation_methods\n",
    "    for method in methods:\n",
    "        exp = explanations[method]\n",
    "        for i in range(len(exp)):\n",
    "            exp[i] = exp[i].cpu().detach()\n",
    "        explanations[method] = torch.cat(exp)\n",
    "    \n",
    "    return files, explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data loader and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = None\n",
    "if RUN_ON_TEST_SET_SAMPLE:\n",
    "    loader = [next(iter(ds_loader))]\n",
    "else:\n",
    "    loader = ds_loader\n",
    "    \n",
    "methods = ['Saliency', 'GuidedGradCam', 'GuidedBackprop', 'LRP', 'IntegratedGradients', 'GradientShap', 'DeepLift', 'Occlusion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate explanations for InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting explanations of Saliency...\n",
      "Getting explanations of GuidedGradCam...\n",
      "Getting explanations of GuidedBackprop...\n",
      "Getting explanations of LRP...\n",
      "Getting explanations of IntegratedGradients...\n",
      "Getting explanations of GradientShap...\n",
      "Getting explanations of DeepLift...\n",
      "Getting explanations of Occlusion...\n",
      "CPU times: total: 3min 51s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_files, explanations_inceptionv3 = run(blackbox_configs, 'InceptionV3', loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate explanations for ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting explanations of Saliency...\n",
      "Getting explanations of GuidedGradCam...\n",
      "Getting explanations of GuidedBackprop...\n",
      "Getting explanations of LRP...\n",
      "Getting explanations of IntegratedGradients...\n",
      "Getting explanations of GradientShap...\n",
      "Getting explanations of DeepLift...\n",
      "Getting explanations of Occlusion...\n",
      "CPU times: total: 10min 42s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_, explanations_resnet = run(blackbox_configs, 'ResNet', loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dir_if_not_exist(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_explanations(path, methods, explanations):\n",
    "    for method in methods:\n",
    "        torch.save(explanations[method], os.path.join(path, f'{method}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_EXPLANATIONS_PARENT_DIR = 'explanations'\n",
    "INCEPTIONV3_DIR = os.path.join(SAVED_EXPLANATIONS_PARENT_DIR, 'InceptionV3')\n",
    "RESNET_DIR = os.path.join(SAVED_EXPLANATIONS_PARENT_DIR, 'ResNet')\n",
    "\n",
    "make_dir_if_not_exist(SAVED_EXPLANATIONS_PARENT_DIR)\n",
    "make_dir_if_not_exist(INCEPTIONV3_DIR)\n",
    "make_dir_if_not_exist(RESNET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_explanations(INCEPTIONV3_DIR, methods, explanations_inceptionv3)\n",
    "save_explanations(RESNET_DIR, methods, explanations_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(SAVED_EXPLANATIONS_PARENT_DIR, 'test_files.json'), 'w') as f:\n",
    "    json.dump(test_files, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
