\subsection{Perturbation-based methods}
\label{subsec:perturbationMethods}
% Khác với các phương pháp gradient-based, những phương pháp perturbation-based phân tích cách các kết quả dự đoán của mô hình thay đổi khi một hoặc nhiều đặc trưng đầu vào bị biến đổi, điều này khiến cho các phương pháp này trở thành lựa chọn tối ưu cho việc phân tích độ nhạy cảm (sensitivity) của các mô hình \cite{gradientBased}. Phân tích độ nhạy cảm của các mô hình trở nên đặc biệt quan trọng khi ta phải đối mặt với những cuộc tấn công mà ở đó những thay đổi ở đầu vào được thiết kế một cách cẩn thận nhằm mục đích cố ý thay đổi kết quả đầu ra của mô hình - "adversarial attack" \cite{adversarialAttacks}. Các phương pháp perturbation-based chỉ cần thực hiện một hoặc nhiều lần chuyển tiếp nhưng lại tốn rất nhiều chi phí tính toán so với các phương pháp gradient-based do phải thực nghiệm trên tập gồm càng nhiều biến động được tạo ra càng tốt. Ngoài ra, kết quả đầu ra của các phương pháp này không mang tính tổng quát mà chỉ chính xác với tập những biến động mà chúng ta tạo ra khi thử nghiệm.
Unlike gradient-based methods, perturbation-based methods analyze how the model's predictions change when one or more input features are perturbed. These perturbations can be in the form of adding noise, modifying pixel values, or altering specific features in a controlled manner. By observing how the model's predictions change in response to these perturbations, we can gain insights into the importance and impact of different features on the model's decision-making process.

The process of perturbation-based analysis typically involves generating multiple perturbed versions of the input and evaluating the model's predictions for each perturbed instance. This analysis provides a more comprehensive understanding of how variations in input features influence the model's output. This characteristic makes perturbation-based methods an optimal choice for analyzing the sensitivity of models \cite{gradientBased}. Analyzing the sensitivity of models becomes particularly important when dealing with attacks where carefully crafted input modifications intentionally aim to alter the model's output, known as ``adversarial attack'' \cite{adversarialAttacks}.  

However, perturbation-based methods come with computational costs due to the need for generating and evaluating a large number of perturbed samples. The generated perturbations should ideally cover a diverse range of possible variations to ensure a robust analysis. Furthermore, perturbation-based methods require multiple forward passes which are computationally expensive compared to gradient-based methods since they need to experiment with a diverse set of generated perturbations. This computational burden limits the scalability and efficiency of perturbation-based methods, especially when dealing with complex models and high-dimensional input spaces.

It is worth noting that the results obtained from perturbation-based methods are specific to the generated sample and may not capture the model's behavior under all possible samples in input space. Therefore, the interpretability provided by perturbation-based methods is constrained to the tested perturbations and may not fully represent the model's general behavior.

\subsubsection{Occlusion}
\label{subsubsec:occlusion}
%Occlusion là một phương pháp giải thích đánh giá đóng góp của từng vùng cụ thể trong ảnh bằng cách che phủ hoặc làm mờ các vùng quan tâm trong ảnh và theo dõi sự thay đổi trong kết quả đầu ra của mô hình. Gọi giá trị đầu vào ban đầu là $x$, mô hình được thể hiện dưới dạng hàm số $f: \in R^m \rightarrow R^n$ . Một vùng trong ảnh được chọn để occlusion để che phủ, với ảnh đã được che mất một vùng ảnh là $x_occ$, độ đóng góp của vùng ảnh đó  được tính như sau:
The main idea behind the Occlusion technique is to systematically occlude different regions of the input data and observe the resulting changes in the model's predictions \cite{deconv}. By comparing the predictions before and after occlusion, we can infer the importance or relevance of the occluded regions in influencing the model's decision.

To apply the Occlusion method, we slide a predefined occlusion window across the input data, systematically covering different regions. The occlusion window can have various shapes and sizes depending on the nature of the input data. At each occlusion position, we replace the occluded region with a neutral value (e.g., zero or average value) and feed the modified input to the model to obtain a new prediction.

The difference between the original prediction and the prediction with the occlusion indicates the importance of the occluded region. Larger deviations in predictions suggest that the occluded region played a more influential role in the model's decision-making process.

Mathematically, let's denote the original input as $x$ and the occluded input as $\tilde{x}$ obtained by occluding a specific region. The model's prediction on the original input is $f(x)$, and the prediction on the occluded input is $f(\tilde{x})$. The occlusion score, representing the importance of the occluded region, can be calculated using a similarity measure, such as the difference in predictions:
\begin{equation}
\text{Occlusion Score} = f(x) - f(\tilde{x})
\end{equation}

The advantage of Occlusion is that it does not rely on gradient information and can be applied to various types of models, including non-differentiable models. However, its effectiveness depends on the choice of the occlusion window size, shape, and stride, as well as the definition of the neutral value used for occlusion. Additionally, occluding small, local regions may not capture the global interactions between features in the input, potentially leading to limited interpretability.