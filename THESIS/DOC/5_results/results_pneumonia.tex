\subsection{Pneumonia Dataset}
We refer to Appendix \ref{Appendix1} for the disagreement heatmaps depicting the evaluation of explanation methods on the Pneumonia dataset. In this section, we analyze the insights derived from these heatmaps and draw parallels to the patterns of disagreement discussed in Section \ref{subsec:resultPneumothorax}. It is important to note that the metric rank correlation is not applicable to this dataset due to the absence of segmentation masks.

\subsubsection{Structural Similarity Index}
Figure \ref{fig:pneumonia_ssim} displays a comparison of SSIM scores for different explanation methods applied to the Pneumonia dataset (see subsection \ref{subsubsec:pneumonia}). A notable observation is the significant difference in similarity scores between the explanation methods when applied to InceptionV3 and ResNet-101. For InceptionV3, most pairs of explanation methods yield high SSIM scores (above 0.6), indicating a high level of similarity. In contrast, for ResNet-101, only four gradient-based methods, namely GradientSHAP, Guided Backpropagation, Guided Grad-CAM, and Integrated Gradients, exhibit moderate to high similarity. The remaining pairs demonstrate minimal to negligible similarity.

\subsubsection{Feature Agreement \& Sign Agreement}
Figure \ref{fig:pneumonia_fa} and \ref{fig:pneumonia_sa} present the feature agreement and sign agreement scores for the methods on the Pneumonia dataset. Similar to the observations in Figure \ref{fig:featureAgreement} and \ref{fig:signAgreement}, the patterns of disagreement are repeated in the Pneumonia dataset. Pairs of methods that exhibit high agreement with each other, such as Guided Backpropagation and Guided Grad-CAM, consistently maintain their high agreement scores. The decrease in agreement scores for the Saliency pairs and the aforementioned methods, as discussed in Section \ref{subsec:ssim} and illustrated in Figure \ref{fig:featureAgreement}, is also evident in the Pneumonia dataset.