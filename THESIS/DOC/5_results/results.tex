\section{Results}
\label{sec:result}

In this section we discuss the results of our experiment for each of the disagreement metric.

\subsection{Structural Similarity Index Measure}
\label{subsec:ssim}
Figure \ref{fig:ssim} presents a comparison of SSIM scores for various explanation methods. These scores were obtained by averaging the results over the test dataset for each pair of saliency map explanations. The computation of the SSIM score involves using the magnitude of the saliency maps, which is normalized to the range of $[0, 1]$.

The results show that the Guided Backpropagation and Guided GradCAM methods produce the most similar saliency maps among all method pairs. Both methods exhibit high similarity on both InceptionV3 and ResNet classifiers, with scores of 0.95 and 0.83, respectively. The LRP and Guided GradCAM pair comes in second place, with scores of 0.71 on InceptionV3 and 0.7 on ResNet. While the remaining pairs exhibit low to very low similarity, LRP--Guided Backpropagation and Integrated Gradients--Saliency demonstrate notable similarity.

Overall, the difference in SSIM scores between the two black boxes indicates that the inner architecture of the black box to some extent influences the appearance of the output explanations. Most of the scores are lower in ResNet, particularly the pairs Saliency--Guided Backpropagation and Saliency--Guided GradCAM, which show a stark difference in SSIM scores (0.71 and 0.72 reductions, respectively). Occlusion consistently shows lower similarity compared to other pairs for both black boxes because there is a difference in the granularity of the explanations produced by Occlusion and other methods. Figure \ref{fig:shapeComparison} provides a comparison of the shapes of various saliency maps, where the saliency maps produced by Occlusion attribute in windows of pixels, while other saliency maps attribute down to the level of each pixel.

\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{images/results/ssim.png}
    \caption{Pairwise structural similarity indices (SSIM) between explanation methods generating for both black boxes (InceptionV3 and ResNet-101). The SSIM scores are computed using the average score over test set data points. Darker colors imply greater similarity in the structure of the two explanations.}
    \label{fig:ssim}
\end{figure}

% TODO: Visualize the input image and the masked region too
\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{images/results/shape-comparison-inceptionv3.png}
    \caption{Comparison of the saliency maps generated by the experimental methods with respect to InceptionV3 prediction. Lighter colors indicate more salient pixels.}
    \label{fig:shapeComparison}
\end{figure}

\subsection{Feature Agreement}
\label{subsec:featureAgreement}
Figure \ref{fig:featureAgreement} depicts the disagreement between different experiment explanation methods with varying top-$k$ values. The experiments reveal that there is a varying degree of disagreement, but the pair Guided Backpropagation--Guided GradCAM exhibits consistent agreement with each other. Additionally, as $k$ increases, the degree of agreement tends to increase as well.

For InceptionV3, we generally observe that methods with structurally similar saliency maps produce agreeable explanations, while non-structurally similar methods produce higher disagreement. However, this pattern is not consistent when evaluating on ResNet. The agreement scores of LRP with Guided GradCAM and Guided Backpropagation are significantly lower, despite their similar structure. Moreover, the pairs between LRP and Saliency, respectively, with Guided Backpropagation and Guided GradCAM show the highest reduction in agreement scores. For Saliency, the agreement scores with Guided Backpropagation and Guided GradCAM decrease from 0.92 and 0.85 to 0.26 and 0.28, respectively, with InceptionV3 and ResNet-101. In the case of LRP, the scores are 0.5 and 0.49 to 0.083 and 0.082, respectively, with the aforementioned black boxes.

\begin{figure}[p]
    \centering
    \includegraphics[width=\textwidth]{images/results/feature-agreement.png}
    \caption{Feature agreement between different methods with varying top-$k$ value.}
    \label{fig:featureAgreement}
\end{figure}

\subsection{Sign Agreement}
\label{subsec:signAgreement}
\begin{figure}[t]
    \centering
    \includegraphics[width=\textwidth]{images/results/sign-agreement.png}
    \caption{Sign agreement between different methods.}
    \label{fig:signAgreement}
\end{figure}

As the conditions become more stringent, the amount of disagreement tends to increase. Figure \ref{fig:signAgreement} displays the average sign agreement score for pairs of explanation methods. Although the agreement scores for pairs that exhibit high agreement in feature agreement (such as Guided Backprop--Guided GradCAM, Saliency--Integrated Gradients, etc.) decrease, they are still significant compared to other pairs. Many pairs demonstrate very low agreement, with scores lower than 0.1.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/results/saliency-maps-value-distribution-resnet.png}
    \caption{The distributions of the saliency map values (within the top-$k$ magnitude) produced by the explanation methods, evaluating on ResNet model.}
    \label{fig:saliencyMapsValueDistributionResnet}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/results/saliency-maps-value-distribution-inceptionv3.png}
    \caption{The distributions of the saliency map values (within the top-$k$ magnitude) produced by the explanation methods, evaluating on InceptionV3 model.}
    \label{fig:saliencyMapsValueDistributionInceptionV3}
\end{figure}

An interesting observation from this result is that most of the sign agreement scores for all pairs are approximately half of the corresponding feature agreement scores in both black boxes. This is because most explanation methods (with the exception of Occlusion and Saliency) generate saliency maps with the distribution of the attribution scores having a mean near 0. Figures \ref{fig:saliencyMapsValueDistributionResnet} and \ref{fig:saliencyMapsValueDistributionInceptionV3} illustrate that all gradient-based methods distribute negative and positive values similarly among the most important pixels.

This suggests that the metric sign agreement may not provide useful information when used as a disagreement measure for saliency maps. However, our observations do not negate the potential use of this metric for other types of explanations. We urge further research on different types of explanation methods to confirm its usefulness.

\subsection{Rank Correlation}
\label{subsec:rankCorrelation}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{images/results/rank-correlation.png}
    \caption{Rank correlation between different methods}
    \label{fig:rankCorrelation}
\end{figure}
In this section, we present the disagreement scores between explanation methods when using the metric rank correlation. The scores are summarized in figure \ref{fig:rankCorrelation} and are computed on instances where pneumothorax masks are available (i.e., instances where the ground-truth label is has-pneumothorax). Computing the rank correlation score with respect to the ground-truth masks provides insight into how agreeable the explanation methods are in considering the relative importance of pixels in the ground-truth area. In simpler terms, the metric indicates whether two saliency maps consistently consider the importance ranking of pixels in the actual pneumothorax area for the black box's decision.

The results show that highly agreeable pairs, as shown in previous experiments, remain consistent with each other in rank correlation, while pairs that strongly disagree with each other also remain that way.

\subsection{Overall Discussion}
One key observation from the analysis of the four metrics is that the agreement scores exhibit considerable variations when evaluating different black boxes. However, in general, on the same black box, the relative degree of disagreement between pairs of explanation methods tends to remain consistent for all metrics. For instance, highly agreeing pairs such as Guided GradCAM--Guided Backpropagation produce high scores for all four criteria. The pairs Saliency--Guided GradCAM and Saliency--Guided Backpropagation consistently agree with each other when explaining for InceptionV3 and consistently disagree with each other when explaining for ResNet.

Gradient-based method explanations generally exhibit higher agreement with each other than perturbation-based methods when evaluating for InceptionV3. However, the situation becomes more complicated when using ResNet. In conclusion, we believe that the level of disagreement is dependent on the kind of black box employed, which contradicts the claim from \cite{disagreementCounterfactual} that the size of the disagreement problem is not dependent on the classifier. We suggest that more research be conducted to provide a conclusive answer to this phenomenon.