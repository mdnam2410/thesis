\section{Experiments}
To evaluate post-hoc XAI methods, our experiment consists of two stages. In the first stage, we train black boxes on the X-ray image classification task. In the second stage, we apply XAI methods to the trained models to gain insights into their decision-making process and interpret the underlying factors that contribute to their predictions. By analyzing the explanations provided by the XAI methods, we aim to understand the model's behavior and assess its transparency and interpretability.



The development environment in which the experiments were conducted are summarized in table \ref{table:env}.


\input{5_results/dataset}

\begin{table}[h!]
\caption{Experiment environments and requirements.}\label{table:env}
\centering
\begin{tabular}{ll}
\hline
CPU   & Intel(R) Xeon(R) CPU @ 2.20GHz \\
\hline
RAM                         &1$\times $13GB \\
\hline
GPU (number and type)                         & NVIDIA TESLA P100 GPUs 16GB\\
\hline
CUDA version                  & 11.6\\                          \hline
Programming language                 & Python 3.10\\ 
\hline
\end{tabular}
\end{table}

% \vspace{-0.5cm}

\subsection{Training Stage}
In the training stage, we trained the InceptionV3 \cite{inceptionv3} and Resnet101 \cite{resnet101} models using popular tools such as pytorch, torchvision, scikit-learn, and pandas. Both models were initially pre-trained on the ImageNet dataset \cite{imageNet}, which provided them with a strong foundation in recognizing and classifying various features. To adapt these models to our specific task of pneumothorax classification, we further trained them using the Chest X-ray Images with Pneumothorax Masks dataset \cite{pneumothorax}. Before training the models, we performed preprocessing on the chest X-ray images. This involved normalization, where the image is transformed such that its mean $\mu$ is (0.485, 0.456, 0.406) and its standard deviation $\sigma$ is (0.229, 0.224, 0.225). This normalization step helps to standardize the input data and improve the training process. Additionally, we resized the images to a specific dimension with length and width in pixels, respectively: (299, 299) for InceptionV3 and (244, 244) for ResNet101. This resizing ensured that the images were compatible with the input requirements of each model. The models were trained using the classification task, aiming to categorize whether a given chest X-ray image exhibited signs of pneumothorax or not. For this binary classification task, we employed the cross-entropy loss function, which is commonly used for training classification models. The optimization of the models was carried out using the Adam optimizer, a popular choice known for its efficiency in handling complex models. The training process spanned 30 epochs, allowing the models to iteratively learn and improve their performance. Throughout the training phase, we monitored the models' progress and selected the best-performing state based on their performance on the validation set.

\subsection{Analysis Stage}
In the XAI analysis stage, we employed XAI methods provided by the Captum framework to generate explanations for the predictions made by our trained models. To measure the disagreement between these explanations, we implement some metrics introduced in \ref{subsec:metrics} by using popular python libraries such as numpy, torch, and skimage to perform the necessary calculations and computations. Once the metrics were computed, we visualized the results to gain a better understanding of the differences and similarities among the XAI methods by using seaborn library.