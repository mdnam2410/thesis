{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT7cVH6V85Ck",
        "outputId": "2e065624-fdc7-41b7-f17e-e43ace78afcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: virtualenv in /usr/local/lib/python3.10/dist-packages (20.23.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (0.3.6)\n",
            "Requirement already satisfied: filelock<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.12.0)\n",
            "Requirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv) (3.3.0)\n",
            "created virtual environment CPython3.10.11.final.0-64 in 567ms\n",
            "  creator CPython3Posix(dest=/content/XAIEnv, clear=False, no_vcs_ignore=False, global=False)\n",
            "  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, wheel=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n",
            "    added seed packages: Flask==2.2.3, Jinja2==3.1.2, MarkupSafe==2.1.2, Pillow==9.5.0, PyWavelets==1.4.1, Pygments==2.15.1, Werkzeug==2.2.3, ansi2html==1.8.0, asttokens==2.2.1, backcall==0.2.0, cachetools==5.3.0, captum==0.6.0, certifi==2023.5.7, charset_normalizer==3.1.0, click==8.1.3, cloudpickle==2.2.1, cmake==3.26.3, comm==0.1.3, contourpy==1.0.7, cycler==0.11.0, dash==2.10.0, dash_bootstrap_components==1.4.1, dash_core_components==2.0.0, dash_html_components==2.0.0, dash_table==5.0.0, debugpy==1.6.7, decorator==5.1.1, dill==0.3.6, executing==1.2.0, fastcore==1.5.29, filelock==3.12.0, fonttools==4.39.4, hnswlib==0.7.0, idna==3.4, imageio==2.29.0, ipykernel==6.23.1, ipython==8.13.2, itsdangerous==2.1.2, jedi==0.18.2, joblib==1.2.0, jupyter_client==8.2.0, jupyter_core==5.3.0, jupyter_dash==0.4.2, kiwisolver==1.4.4, lazy_loader==0.2, lime==0.2.0.1, lit==16.0.5, llvmlite==0.40.0, matplotlib==3.7.1, matplotlib_inline==0.1.6, mpmath==1.3.0, multiprocess==0.70.14, nest_asyncio==1.5.6, networkx==3.1, numba==0.57.0, numpy==1.22.4, nvidia_cublas_cu11==11.10.3.66, nvidia_cuda_cupti_cu11==11.7.101, nvidia_cuda_nvrtc_cu11==11.7.99, nvidia_cuda_runtime_cu11==11.7.99, nvidia_cudnn_cu11==8.5.0.96, nvidia_cufft_cu11==10.9.0.58, nvidia_curand_cu11==10.2.10.91, nvidia_cusolver_cu11==11.4.0.1, nvidia_cusparse_cu11==11.7.4.91, nvidia_nccl_cu11==2.14.3, nvidia_nvtx_cu11==11.7.91, omnixai==1.2.5, opencv_python==4.7.0.72, opencv_python_headless==4.7.0.72, packaging==23.1, pandas==2.0.1, parso==0.8.3, patsy==0.5.3, pexpect==4.8.0, pickleshare==0.7.5, pip==23.1.2, platformdirs==3.5.1, plotly==5.14.1, prompt_toolkit==3.0.38, psutil==5.9.5, ptyprocess==0.7.0, pure_eval==0.2.2, pyparsing==3.0.9, python_dateutil==2.8.2, pytz==2023.3, pyzmq==25.1.0, quantus==0.4.0, requests==2.31.0, retrying==1.3.4, salib==1.4.7, scikit_image==0.20.0, scikit_learn==1.1.3, scipy==1.10.1, setuptools==67.7.2, shap==0.41.0, six==1.16.0, slicer==0.0.7, stack_data==0.6.2, statsmodels==0.14.0, sympy==1.12, tabulate==0.9.0, tenacity==8.2.2, threadpoolctl==3.1.0, tifffile==2023.4.12, torch==2.0.1, torchvision==0.15.2, tornado==6.3.2, tqdm==4.65.0, traitlets==5.9.0, triton==2.0.0, typing_extensions==4.6.2, tzdata==2023.3, urllib3==2.0.2, wcwidth==0.2.6, wheel==0.40.0\n",
            "  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\n"
          ]
        }
      ],
      "source": [
        "!pip install virtualenv\n",
        "!virtualenv XAIEnv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD21R-paOIB-",
        "outputId": "bcbc1b39-805e-47c5-b3dd-3e56bd64b86a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-27 07:24:50--  https://drive.google.com/uc?export=download&id=1KefgyStyr4xcEqlrJjlPevdH99jkcZ4J\n",
            "Resolving drive.google.com (drive.google.com)... 64.233.170.139, 64.233.170.102, 64.233.170.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|64.233.170.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0s-8c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ffuq3mm50vpe388hmopn5ledo48eutue/1685172225000/07295101801107701363/*/1KefgyStyr4xcEqlrJjlPevdH99jkcZ4J?e=download&uuid=8af1afa2-5ce4-4ace-adcd-a053a81680d6 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-05-27 07:24:51--  https://doc-0s-8c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ffuq3mm50vpe388hmopn5ledo48eutue/1685172225000/07295101801107701363/*/1KefgyStyr4xcEqlrJjlPevdH99jkcZ4J?e=download&uuid=8af1afa2-5ce4-4ace-adcd-a053a81680d6\n",
            "Resolving doc-0s-8c-docs.googleusercontent.com (doc-0s-8c-docs.googleusercontent.com)... 74.125.24.132, 2404:6800:4003:c03::84\n",
            "Connecting to doc-0s-8c-docs.googleusercontent.com (doc-0s-8c-docs.googleusercontent.com)|74.125.24.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69 [application/json]\n",
            "Saving to: ‘kaggle.json’\n",
            "\n",
            "kaggle.json         100%[===================>]      69  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-27 07:24:51 (3.09 MB/s) - ‘kaggle.json’ saved [69/69]\n",
            "\n",
            "{\"username\":\"binhhuunguyen\",\"key\":\"490f5d1951771fb1c83d0a8b116a325b\"}"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files \n",
        "# files.upload()\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1KefgyStyr4xcEqlrJjlPevdH99jkcZ4J' -O kaggle.json\n",
        "!cat kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ7VowTTEBks"
      },
      "source": [
        "# Explain Classification result from ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMqKUO1q9vs7",
        "outputId": "9b03fc9a-aeb7-4466-af93-b3c0d48c8c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m543.8/543.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!source /content/XAIEnv/bin/activate; pip install -q numba torch captum torchvision quantus omnixai[vision] dash jupyter_dash dash_bootstrap_components scikit-learn==1.1.3 numpy==1.22.4 Pillow fastcore -I -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yweYyg0OLsJR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"XAIEnv/lib/python3.10/site-packages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mk4hn6mXOYIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcf3a0c3-e646-411c-8143-2c129e41de58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXunAuMEOwV5",
        "outputId": "55871e9d-dc66-4006-990d-e0ec89840ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading pneumothorax-chest-xray-images-and-masks.zip to /content/datasets\n",
            "100% 4.50G/4.50G [03:57<00:00, 23.0MB/s]\n",
            "100% 4.50G/4.50G [03:57<00:00, 20.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d vbookshelf/pneumothorax-chest-xray-images-and-masks -p /content/datasets/ --unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9YpVFVMvQHb",
        "outputId": "7462d991-3a99-4894-ac70-d43dc8094b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading xai-pretrained-blackbox.zip to /content/datasets\n",
            " 99% 252M/255M [00:18<00:00, 13.8MB/s]\n",
            "100% 255M/255M [00:18<00:00, 14.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d binhhuunguyen/xai-pretrained-blackbox  -p /content/datasets/ --unzip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erPY0MqyEU_X",
        "outputId": "ab96283a-4242-46c0-e130-338e7742e546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda for inference\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import quantus\n",
        "from captum.attr import (\n",
        "    Saliency, # A baseline approach for computing input attribution\n",
        "    GradientShap, \n",
        "    DeepLift,\n",
        "    DeepLiftShap,\n",
        "    IntegratedGradients,\n",
        "    LayerConductance,\n",
        "    NeuronConductance,\n",
        "    NoiseTunnel,\n",
        "    GuidedGradCam,\n",
        "    GuidedBackprop,\n",
        "    Saliency,\n",
        "    LimeBase,\n",
        "    FeatureAblation,\n",
        "    Occlusion,\n",
        "    LRP,\n",
        "    visualization as viz\n",
        ")\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import json\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as c_map\n",
        "from torchvision import models\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "cpu = torch.device(\"cpu\")\n",
        "print(f'Using {device} for inference')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLfyNmtEM1SB"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVH_ZzSPDGKc"
      },
      "outputs": [],
      "source": [
        "resize_image = transforms.Compose([\n",
        "  transforms.Resize(256),\n",
        "  transforms.CenterCrop(299),\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([            \n",
        "  transforms.ToTensor(),\n",
        "  resize_image,\n",
        "  transforms.Normalize(\n",
        "   mean=[0.485, 0.456, 0.406],\n",
        "   std=[0.229, 0.224, 0.225]\n",
        "  )\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([            \n",
        "  transforms.ToTensor(),\n",
        "  resize_image,\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIEBF6WUzAQA"
      },
      "source": [
        "# Setup datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ncf8jeMzDYz"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PneumothoraxImageDataset(Dataset):\n",
        "    def __init__(self, images, targets, masks, transform, mask_transform):\n",
        "        self.masks = masks\n",
        "        self.images = images\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "        self.mask_transform = mask_transform\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.asarray(Image.open(self.images[idx]).convert(\"RGB\"))\n",
        "        mask = np.asarray(Image.open(self.masks[idx]).convert(\"RGB\"))\n",
        "        label = self.targets[idx]\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "        if self.mask_transform:\n",
        "          mask = self.mask_transform(mask)\n",
        "        return image, mask, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G-yx78yQsMn"
      },
      "outputs": [],
      "source": [
        "main_path = '/content/datasets/siim-acr-pneumothorax'\n",
        "import os\n",
        "import pandas as pd\n",
        "# train_data = pd.read_csv(os.path.join(main_path, 'stage_1_train_images.csv'))\n",
        "test_data = pd.read_csv(os.path.join(main_path, 'stage_1_test_images.csv'))\n",
        "# Just load only abnormal cases\n",
        "test_abnormal = test_data.loc[test_data.has_pneumo == 1]\n",
        "\n",
        "# train_data['images'] = train_data['new_filename'].apply(lambda x: os.path.join(main_path, 'png_images', x))\n",
        "# train_data['masks'] = train_data['new_filename'].apply(lambda x: os.path.join(main_path, 'png_masks', x))\n",
        "\n",
        "test_abnormal['images'] = test_abnormal['new_filename'].apply(lambda x: os.path.join(main_path, 'png_images', x))\n",
        "test_abnormal['masks'] = test_abnormal['new_filename'].apply(lambda x: os.path.join(main_path, 'png_masks', x))\n",
        "\n",
        "images = test_abnormal['images'].tolist()\n",
        "masks = test_abnormal['masks'].tolist()\n",
        "targets = test_abnormal['has_pneumo'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbo2-sZMQ1iU"
      },
      "outputs": [],
      "source": [
        "dataset = PneumothoraxImageDataset(images, targets, masks, transform=transform, mask_transform=mask_transform)\n",
        "ds_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQ48mhhkR_Qt",
        "outputId": "d9f9e0c9-71ce-4f6b-f9d3-97412a6385db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3, 299, 299]) torch.Size([8, 3, 299, 299])\n"
          ]
        }
      ],
      "source": [
        "x, mask, y = next(iter(ds_loader))\n",
        "print(x.shape, mask.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3prfR5sZf1Jj"
      },
      "source": [
        "## UTIL FUNCS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcX0anjnj3SR"
      },
      "source": [
        "### Bellow is the override of an visualization implementation due to the orginal version from the captum module cause bug when config matplotlib grid_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eJieH7DcEHO"
      },
      "outputs": [],
      "source": [
        "from matplotlib import cm, colors, pyplot as plt\n",
        "from matplotlib.collections import LineCollection\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from matplotlib.figure import Figure\n",
        "from matplotlib.pyplot import axis, figure\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from numpy import ndarray\n",
        "from enum import Enum\n",
        "from typing import Any, Iterable, List, Optional, Tuple, Union\n",
        "\n",
        "\n",
        "try:\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    HAS_IPYTHON = True\n",
        "except ImportError:\n",
        "    HAS_IPYTHON = False\n",
        "\n",
        "\n",
        "class ImageVisualizationMethod(Enum):\n",
        "    heat_map = 1\n",
        "    blended_heat_map = 2\n",
        "    original_image = 3\n",
        "    masked_image = 4\n",
        "    alpha_scaling = 5\n",
        "\n",
        "\n",
        "class TimeseriesVisualizationMethod(Enum):\n",
        "    overlay_individual = 1\n",
        "    overlay_combined = 2\n",
        "    colored_graph = 3\n",
        "\n",
        "\n",
        "class VisualizeSign(Enum):\n",
        "    positive = 1\n",
        "    absolute_value = 2\n",
        "    negative = 3\n",
        "    all = 4\n",
        "\n",
        "\n",
        "def _prepare_image(attr_visual: ndarray):\n",
        "    return np.clip(attr_visual.astype(int), 0, 255)\n",
        "\n",
        "\n",
        "def _normalize_scale(attr: ndarray, scale_factor: float):\n",
        "    assert scale_factor != 0, \"Cannot normalize by scale factor = 0\"\n",
        "    if abs(scale_factor) < 1e-5:\n",
        "        warnings.warn(\n",
        "            \"Attempting to normalize by value approximately 0, visualized results\"\n",
        "            \"may be misleading. This likely means that attribution values are all\"\n",
        "            \"close to 0.\"\n",
        "        )\n",
        "    attr_norm = attr / scale_factor\n",
        "    return np.clip(attr_norm, -1, 1)\n",
        "\n",
        "\n",
        "def _cumulative_sum_threshold(values: ndarray, percentile: Union[int, float]):\n",
        "    # given values should be non-negative\n",
        "    assert percentile >= 0 and percentile <= 100, (\n",
        "        \"Percentile for thresholding must be \" \"between 0 and 100 inclusive.\"\n",
        "    )\n",
        "    sorted_vals = np.sort(values.flatten())\n",
        "    cum_sums = np.cumsum(sorted_vals)\n",
        "    threshold_id = np.where(cum_sums >= cum_sums[-1] * 0.01 * percentile)[0][0]\n",
        "    return sorted_vals[threshold_id]\n",
        "\n",
        "\n",
        "def _normalize_attr(\n",
        "    attr: ndarray,\n",
        "    sign: str,\n",
        "    outlier_perc: Union[int, float] = 2,\n",
        "    reduction_axis: Optional[int] = None,\n",
        "):\n",
        "    attr_combined = attr\n",
        "    if reduction_axis is not None:\n",
        "        attr_combined = np.sum(attr, axis=reduction_axis)\n",
        "\n",
        "    # Choose appropriate signed values and rescale, removing given outlier percentage.\n",
        "    if VisualizeSign[sign] == VisualizeSign.all:\n",
        "        threshold = _cumulative_sum_threshold(np.abs(attr_combined), 100 - outlier_perc)\n",
        "    elif VisualizeSign[sign] == VisualizeSign.positive:\n",
        "        attr_combined = (attr_combined > 0) * attr_combined\n",
        "        threshold = _cumulative_sum_threshold(attr_combined, 100 - outlier_perc)\n",
        "    elif VisualizeSign[sign] == VisualizeSign.negative:\n",
        "        attr_combined = (attr_combined < 0) * attr_combined\n",
        "        threshold = -1 * _cumulative_sum_threshold(\n",
        "            np.abs(attr_combined), 100 - outlier_perc\n",
        "        )\n",
        "    elif VisualizeSign[sign] == VisualizeSign.absolute_value:\n",
        "        attr_combined = np.abs(attr_combined)\n",
        "        threshold = _cumulative_sum_threshold(attr_combined, 100 - outlier_perc)\n",
        "    else:\n",
        "        raise AssertionError(\"Visualize Sign type is not valid.\")\n",
        "    return _normalize_scale(attr_combined, threshold)\n",
        "\n",
        "\n",
        "def visualize_image_attr(\n",
        "    attr: ndarray,\n",
        "    original_image: Union[None, ndarray] = None,\n",
        "    method: str = \"heat_map\",\n",
        "    sign: str = \"absolute_value\",\n",
        "    plt_fig_axis: Union[None, Tuple[figure, axis]] = None,\n",
        "    outlier_perc: Union[int, float] = 2,\n",
        "    cmap: Union[None, str] = None,\n",
        "    alpha_overlay: float = 0.5,\n",
        "    show_colorbar: bool = False,\n",
        "    title: Union[None, str] = None,\n",
        "    fig_size: Tuple[int, int] = (6, 6),\n",
        "    use_pyplot: bool = True,\n",
        "):\n",
        "    r\"\"\"\n",
        "    Visualizes attribution for a given image by normalizing attribution values\n",
        "    of the desired sign (positive, negative, absolute value, or all) and displaying\n",
        "    them using the desired mode in a matplotlib figure.\n",
        "\n",
        "    Args:\n",
        "\n",
        "        attr (numpy.ndarray): Numpy array corresponding to attributions to be\n",
        "                    visualized. Shape must be in the form (H, W, C), with\n",
        "                    channels as last dimension. Shape must also match that of\n",
        "                    the original image if provided.\n",
        "        original_image (numpy.ndarray, optional): Numpy array corresponding to\n",
        "                    original image. Shape must be in the form (H, W, C), with\n",
        "                    channels as the last dimension. Image can be provided either\n",
        "                    with float values in range 0-1 or int values between 0-255.\n",
        "                    This is a necessary argument for any visualization method\n",
        "                    which utilizes the original image.\n",
        "                    Default: None\n",
        "        method (str, optional): Chosen method for visualizing attribution.\n",
        "                    Supported options are:\n",
        "\n",
        "                    1. `heat_map` - Display heat map of chosen attributions\n",
        "\n",
        "                    2. `blended_heat_map` - Overlay heat map over greyscale\n",
        "                       version of original image. Parameter alpha_overlay\n",
        "                       corresponds to alpha of heat map.\n",
        "\n",
        "                    3. `original_image` - Only display original image.\n",
        "\n",
        "                    4. `masked_image` - Mask image (pixel-wise multiply)\n",
        "                       by normalized attribution values.\n",
        "\n",
        "                    5. `alpha_scaling` - Sets alpha channel of each pixel\n",
        "                       to be equal to normalized attribution value.\n",
        "\n",
        "                    Default: `heat_map`\n",
        "        sign (str, optional): Chosen sign of attributions to visualize. Supported\n",
        "                    options are:\n",
        "\n",
        "                    1. `positive` - Displays only positive pixel attributions.\n",
        "\n",
        "                    2. `absolute_value` - Displays absolute value of\n",
        "                       attributions.\n",
        "\n",
        "                    3. `negative` - Displays only negative pixel attributions.\n",
        "\n",
        "                    4. `all` - Displays both positive and negative attribution\n",
        "                       values. This is not supported for `masked_image` or\n",
        "                       `alpha_scaling` modes, since signed information cannot\n",
        "                       be represented in these modes.\n",
        "\n",
        "                    Default: `absolute_value`\n",
        "        plt_fig_axis (tuple, optional): Tuple of matplotlib.pyplot.figure and axis\n",
        "                    on which to visualize. If None is provided, then a new figure\n",
        "                    and axis are created.\n",
        "                    Default: None\n",
        "        outlier_perc (float or int, optional): Top attribution values which\n",
        "                    correspond to a total of outlier_perc percentage of the\n",
        "                    total attribution are set to 1 and scaling is performed\n",
        "                    using the minimum of these values. For sign=`all`, outliers\n",
        "                    and scale value are computed using absolute value of\n",
        "                    attributions.\n",
        "                    Default: 2\n",
        "        cmap (str, optional): String corresponding to desired colormap for\n",
        "                    heatmap visualization. This defaults to \"Reds\" for negative\n",
        "                    sign, \"Blues\" for absolute value, \"Greens\" for positive sign,\n",
        "                    and a spectrum from red to green for all. Note that this\n",
        "                    argument is only used for visualizations displaying heatmaps.\n",
        "                    Default: None\n",
        "        alpha_overlay (float, optional): Alpha to set for heatmap when using\n",
        "                    `blended_heat_map` visualization mode, which overlays the\n",
        "                    heat map over the greyscaled original image.\n",
        "                    Default: 0.5\n",
        "        show_colorbar (bool, optional): Displays colorbar for heatmap below\n",
        "                    the visualization. If given method does not use a heatmap,\n",
        "                    then a colormap axis is created and hidden. This is\n",
        "                    necessary for appropriate alignment when visualizing\n",
        "                    multiple plots, some with colorbars and some without.\n",
        "                    Default: False\n",
        "        title (str, optional): Title string for plot. If None, no title is\n",
        "                    set.\n",
        "                    Default: None\n",
        "        fig_size (tuple, optional): Size of figure created.\n",
        "                    Default: (6,6)\n",
        "        use_pyplot (bool, optional): If true, uses pyplot to create and show\n",
        "                    figure and displays the figure after creating. If False,\n",
        "                    uses Matplotlib object oriented API and simply returns a\n",
        "                    figure object without showing.\n",
        "                    Default: True.\n",
        "\n",
        "    Returns:\n",
        "        2-element tuple of **figure**, **axis**:\n",
        "        - **figure** (*matplotlib.pyplot.figure*):\n",
        "                    Figure object on which visualization\n",
        "                    is created. If plt_fig_axis argument is given, this is the\n",
        "                    same figure provided.\n",
        "        - **axis** (*matplotlib.pyplot.axis*):\n",
        "                    Axis object on which visualization\n",
        "                    is created. If plt_fig_axis argument is given, this is the\n",
        "                    same axis provided.\n",
        "\n",
        "    Examples::\n",
        "\n",
        "        >>> # ImageClassifier takes a single input tensor of images Nx3x32x32,\n",
        "        >>> # and returns an Nx10 tensor of class probabilities.\n",
        "        >>> net = ImageClassifier()\n",
        "        >>> ig = IntegratedGradients(net)\n",
        "        >>> # Computes integrated gradients for class 3 for a given image .\n",
        "        >>> attribution, delta = ig.attribute(orig_image, target=3)\n",
        "        >>> # Displays blended heat map visualization of computed attributions.\n",
        "        >>> _ = visualize_image_attr(attribution, orig_image, \"blended_heat_map\")\n",
        "    \"\"\"\n",
        "    # Create plot if figure, axis not provided\n",
        "    if plt_fig_axis is not None:\n",
        "        plt_fig, plt_axis = plt_fig_axis\n",
        "    else:\n",
        "        if use_pyplot:\n",
        "            plt_fig, plt_axis = plt.subplots(figsize=fig_size)\n",
        "        else:\n",
        "            plt_fig = Figure(figsize=fig_size)\n",
        "            plt_axis = plt_fig.subplots()\n",
        "\n",
        "    if original_image is not None:\n",
        "        if np.max(original_image) <= 1.0:\n",
        "            original_image = _prepare_image(original_image * 255)\n",
        "    elif ImageVisualizationMethod[method] != ImageVisualizationMethod.heat_map:\n",
        "        raise ValueError(\n",
        "            \"Original Image must be provided for\"\n",
        "            \"any visualization other than heatmap.\"\n",
        "        )\n",
        "\n",
        "    # Remove ticks and tick labels from plot.\n",
        "    plt_axis.xaxis.set_ticks_position(\"none\")\n",
        "    plt_axis.yaxis.set_ticks_position(\"none\")\n",
        "    plt_axis.set_yticklabels([])\n",
        "    plt_axis.set_xticklabels([])\n",
        "    plt_axis.grid(visible=False)\n",
        "\n",
        "    heat_map = None\n",
        "    # Show original image\n",
        "    if ImageVisualizationMethod[method] == ImageVisualizationMethod.original_image:\n",
        "        assert (\n",
        "            original_image is not None\n",
        "        ), \"Original image expected for original_image method.\"\n",
        "        if len(original_image.shape) > 2 and original_image.shape[2] == 1:\n",
        "            original_image = np.squeeze(original_image, axis=2)\n",
        "        plt_axis.imshow(original_image)\n",
        "    else:\n",
        "        # Choose appropriate signed attributions and normalize.\n",
        "        norm_attr = _normalize_attr(attr, sign, outlier_perc, reduction_axis=2)\n",
        "\n",
        "        # Set default colormap and bounds based on sign.\n",
        "        if VisualizeSign[sign] == VisualizeSign.all:\n",
        "            default_cmap = LinearSegmentedColormap.from_list(\n",
        "                \"RdWhGn\", [\"red\", \"white\", \"green\"]\n",
        "            )\n",
        "            vmin, vmax = -1, 1\n",
        "        elif VisualizeSign[sign] == VisualizeSign.positive:\n",
        "            default_cmap = \"Greens\"\n",
        "            vmin, vmax = 0, 1\n",
        "        elif VisualizeSign[sign] == VisualizeSign.negative:\n",
        "            default_cmap = \"Reds\"\n",
        "            vmin, vmax = 0, 1\n",
        "        elif VisualizeSign[sign] == VisualizeSign.absolute_value:\n",
        "            default_cmap = \"Blues\"\n",
        "            vmin, vmax = 0, 1\n",
        "        else:\n",
        "            raise AssertionError(\"Visualize Sign type is not valid.\")\n",
        "        cmap = cmap if cmap is not None else default_cmap\n",
        "\n",
        "        # Show appropriate image visualization.\n",
        "        if ImageVisualizationMethod[method] == ImageVisualizationMethod.heat_map:\n",
        "            heat_map = plt_axis.imshow(norm_attr, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "        elif (\n",
        "            ImageVisualizationMethod[method]\n",
        "            == ImageVisualizationMethod.blended_heat_map\n",
        "        ):\n",
        "            assert (\n",
        "                original_image is not None\n",
        "            ), \"Original Image expected for blended_heat_map method.\"\n",
        "            plt_axis.imshow(np.mean(original_image, axis=2), cmap=\"gray\")\n",
        "            heat_map = plt_axis.imshow(\n",
        "                norm_attr, cmap=cmap, vmin=vmin, vmax=vmax, alpha=alpha_overlay\n",
        "            )\n",
        "        elif ImageVisualizationMethod[method] == ImageVisualizationMethod.masked_image:\n",
        "            assert VisualizeSign[sign] != VisualizeSign.all, (\n",
        "                \"Cannot display masked image with both positive and negative \"\n",
        "                \"attributions, choose a different sign option.\"\n",
        "            )\n",
        "            plt_axis.imshow(\n",
        "                _prepare_image(original_image * np.expand_dims(norm_attr, 2))\n",
        "            )\n",
        "        elif ImageVisualizationMethod[method] == ImageVisualizationMethod.alpha_scaling:\n",
        "            assert VisualizeSign[sign] != VisualizeSign.all, (\n",
        "                \"Cannot display alpha scaling with both positive and negative \"\n",
        "                \"attributions, choose a different sign option.\"\n",
        "            )\n",
        "            plt_axis.imshow(\n",
        "                np.concatenate(\n",
        "                    [\n",
        "                        original_image,\n",
        "                        _prepare_image(np.expand_dims(norm_attr, 2) * 255),\n",
        "                    ],\n",
        "                    axis=2,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            raise AssertionError(\"Visualize Method type is not valid.\")\n",
        "\n",
        "    # Add colorbar. If given method is not a heatmap and no colormap is relevant,\n",
        "    # then a colormap axis is created and hidden. This is necessary for appropriate\n",
        "    # alignment when visualizing multiple plots, some with heatmaps and some\n",
        "    # without.\n",
        "    if show_colorbar:\n",
        "        axis_separator = make_axes_locatable(plt_axis)\n",
        "        colorbar_axis = axis_separator.append_axes(\"bottom\", size=\"5%\", pad=0.1)\n",
        "        if heat_map:\n",
        "            plt_fig.colorbar(heat_map, orientation=\"horizontal\", cax=colorbar_axis)\n",
        "        else:\n",
        "            colorbar_axis.axis(\"off\")\n",
        "    if title:\n",
        "        plt_axis.set_title(title)\n",
        "\n",
        "    if use_pyplot:\n",
        "        plt.show()\n",
        "\n",
        "    return plt_fig, plt_axis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03NSEm1hf5Yk"
      },
      "source": [
        "## Setup Blackbox & XAI methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfEomGL_M8DD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38930239-5403-4122-ece0-cf277e8d5233"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Inception3(\n",
              "  (Conv2d_1a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2b_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Conv2d_3b_1x1): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_4a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Mixed_5b): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5c): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5d): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6a): InceptionB(\n",
              "    (branch3x3): BasicConv2d(\n",
              "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6b): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6c): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6d): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6e): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (AuxLogits): InceptionAux(\n",
              "    (conv0): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (conv1): BasicConv2d(\n",
              "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
              "  )\n",
              "  (Mixed_7a): InceptionD(\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7b): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7c): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "checkpoint = torch.load('/content/datasets/inception_cp.pth')\n",
        "blackbox = models.inception_v3()\n",
        "blackbox.load_state_dict(checkpoint)\n",
        "for parameter in blackbox.parameters():\n",
        "    parameter.requires_grad = False\n",
        "blackbox.eval().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_pjUBZHM9Yf"
      },
      "outputs": [],
      "source": [
        "sl = Saliency(blackbox)\n",
        "guided_gc = GuidedGradCam(blackbox, blackbox.Mixed_7c)\n",
        "gbp = GuidedBackprop(blackbox)\n",
        "lrp = LRP(blackbox)\n",
        "dls = DeepLiftShap(blackbox)\n",
        "dl = DeepLift(blackbox)\n",
        "gs = GradientShap(blackbox)\n",
        "ig = IntegratedGradients(blackbox)\n",
        "ablator = FeatureAblation(blackbox)\n",
        "occlusion = Occlusion(blackbox)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vgOkvGgyCRy"
      },
      "source": [
        "# Generate Explainations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQ8hQhIoOwGo"
      },
      "outputs": [],
      "source": [
        "rand_img_dist = torch.rand(x.shape).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JOP1plyU4uV"
      },
      "outputs": [],
      "source": [
        "dataset_labels = { 0: 'normal', 1: 'Pneumothorax' }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CQamOeyeSlE"
      },
      "outputs": [],
      "source": [
        "xai_methods = {\n",
        "  \"Saliency\": { \"method\": sl , \"options\": {}},\n",
        "  \"GuidedGradCam\": { \"method\": guided_gc, \"options\": {}},\n",
        "  \"GuidedBackprop\": { \"method\": gbp, \"options\": {}},\n",
        "  \"LRP\": { \"method\": lrp, \"options\": {}},\n",
        "  # \"DeepLiftShap\": { \"method\": dls, \"options\": {}},\n",
        "  # \"DeepLift\": { \"method\": dl, \"options\": {}},\n",
        "  \"GradientShap\": { \"method\": gs, \"options\": { 'n_samples': 64, 'stdevs': 0.0001, 'baselines': rand_img_dist }},\n",
        "  \"IntegratedGradients\": { \"method\": ig, \"options\": { 'n_steps' : 150 }, 'baselines': rand_img_dist },\n",
        "  # \"FeatureAblation\": { \"method\": ablator, \"options\": {}},\n",
        "  \"Occlusion\": { \"method\": occlusion, \"options\": { 'sliding_window_shapes': (3,8, 8), 'strides': (3, 4, 4)}}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTCFWTPxHqcK"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "def visualize_explain_of(xai_methods, x, mask, y, blackbox):\n",
        "  with torch.no_grad():\n",
        "    output = torch.nn.functional.softmax(blackbox(x), dim=1)\n",
        "    _, indices = torch.topk(output, k=1, dim = 1)\n",
        "  indices = torch.flatten(indices)\n",
        "  num_methods = len(xai_methods.items())\n",
        "  for idx, img in tqdm(enumerate(x)):\n",
        "    target = indices[idx]\n",
        "    if target.item() == 0:\n",
        "      continue\n",
        "    fig, axes = plt.subplots(1, num_methods + 1, figsize = (48, 6))\n",
        "    axes[0].imshow(np.transpose(mask[idx].detach().numpy(), (1, 2, 0)))\n",
        "    for method_idx, (method_name, parameters) in enumerate(xai_methods.items()):\n",
        "      attributions = parameters[\"method\"].attribute(img.unsqueeze(0), target=target, **parameters[\"options\"])\n",
        "      # Convert the compute attribution tensor into an image-like numpy array\n",
        "      attribution = np.transpose(attributions.squeeze().cpu().detach().numpy(), (1,2,0))\n",
        "      visualize_image_attr(attribution, np.transpose(img.cpu().detach().numpy(), (1, 2,0)), \"blended_heat_map\", sign=\"positive\", title=method_name, use_pyplot=False, plt_fig_axis=(fig, axes[1 + method_idx]))\n",
        "      torch.cuda.empty_cache()\n",
        "      gc.collect()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaD19sOKV-XZ"
      },
      "outputs": [],
      "source": [
        "# visualize_explain_of(xai_methods, x.to(device), mask, y, blackbox)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZudcBlGD0so"
      },
      "source": [
        "# Metrics to compare saliency masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVPLnrnGD8zE"
      },
      "source": [
        "## Mathematical similarity measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypkDRrArMliF"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUwIbTzPEA4y"
      },
      "outputs": [],
      "source": [
        "def get_explanation(xai_config, x, targets):\n",
        "    xai_model = xai_config['method']\n",
        "    options = xai_config['options']\n",
        "    attribution = xai_model.attribute(x, target=targets, **options)\n",
        "    return attribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIGlN7X9H5Aw"
      },
      "outputs": [],
      "source": [
        "def normalize(x):\n",
        "    t = (x - np.min(x)) / (np.max(x) - np.min(x))\n",
        "    return t / t.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX_9KhIeZyAp"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    output = torch.nn.functional.softmax(blackbox(x.to(device)), dim=1)\n",
        "    _, indices = torch.topk(output, k=1, dim = 1)\n",
        "indices = torch.flatten(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thPpWROjcjNd"
      },
      "outputs": [],
      "source": [
        "attribution_saliency = get_explanation(xai_methods['Saliency'], x.to(device)[0], indices[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoXMLvBqFBA_"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(normalize(attribution_saliency.sum(axis=0).mean(axis=0).cpu().detach().numpy()), annot=False, xticklabels=False, yticklabels=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fctnSAv6fMaz"
      },
      "outputs": [],
      "source": [
        "attribution_guidedgc = get_explanation(xai_methods['GradientShap'], x.to(device)[0], indices[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK3SsUr_cwaw"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(normalize(np.abs(attribution_guidedgc.sum(axis=0).mean(axis=0).cpu().detach().numpy())), annot=False, xticklabels=False, yticklabels=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RL2R4rwwej9w"
      },
      "outputs": [],
      "source": [
        "sns.histplot(attribution_saliency.flatten().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XVZcIr4eDsr"
      },
      "outputs": [],
      "source": [
        "sns.histplot(attribution_guidedgc.flatten().cpu().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bY5Z9x0OJC8J"
      },
      "source": [
        "### Bhattacharrya Distance ([wiki](https://en.wikipedia.org/wiki/Bhattacharyya_distance))\n",
        "Measure the similarity between two probability distributions $P$ and $Q$. Formula:\n",
        "$$D(P, Q) = -\\ln(BC(P, Q))$$\n",
        "where:\n",
        "$$BC(P, Q) = \\sum_{x \\in X}\\sqrt{P(x)Q(x)}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4pXnsIOIMM9"
      },
      "outputs": [],
      "source": [
        "def bhattacharyya_distance(x, y):\n",
        "    return -np.log(np.sum(np.sqrt(normalize(x) * normalize(y))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsio8DnZGr75"
      },
      "outputs": [],
      "source": [
        "bhattacharyya_distance(attribution_saliency.cpu().numpy(), np.abs(attribution_guidedgc.cpu().numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gt4pNbEvlS0C"
      },
      "outputs": [],
      "source": [
        "def hellinger_distance(x, y):\n",
        "    return 1 / np.sqrt(2) * np.sqrt(np.sum((np.sqrt(normalize(x)) - np.sqrt(normalize(y))) ** 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb-_8N9VIebw"
      },
      "source": [
        "## Averaging over test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7ERRRRjgM-t"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "def compute_mean_disagreement(method1, method2, x, indices, metric):\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    exp1 = []\n",
        "    exp2 = []\n",
        "    metrics = []\n",
        "    e1 = get_explanation(method1, x, indices)\n",
        "    e2 = get_explanation(method2, x, indices)\n",
        "    metrics.append(metric(e1.cpu().detach().numpy(), e2.cpu().detach().numpy()))\n",
        "    \n",
        "    return np.array(metrics).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93Yjqi24zCns"
      },
      "outputs": [],
      "source": [
        "def compute_disagreement_heatmap(list_methods, x, blackbox, metric):\n",
        "    size = len(list_methods)\n",
        "    result = np.empty((size, size))\n",
        "    with torch.no_grad():\n",
        "        output = torch.nn.functional.softmax(blackbox(x), dim=1)\n",
        "        _, indices = torch.topk(output, k=1, dim = 1)\n",
        "    indices = torch.flatten(indices)\n",
        "\n",
        "    for j in range(size):\n",
        "        for i in range(size):\n",
        "            if i > j:\n",
        "                result[i, j] = compute_mean_disagreement(list_methods[i], list_methods[j], x, indices, metric)\n",
        "            elif i == j:\n",
        "                result[i, j] = 0\n",
        "            else:\n",
        "                result[i, j] = result[j, i]\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(rand_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynmY1DmrFqEk",
        "outputId": "3ecb31a7-f1ef-429c-ab52-42ebc8f88e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfMIiBwhzxSr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "outputId": "adef8b6e-45a7-42bb-e922-01c03baca5eb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-4af58d6f3074>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmethod_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'LRP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GradientShap'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GuidedGradCam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'GuidedBackprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'IntegratedGradients'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_methods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxai_methods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_disagreement_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_methods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblackbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhellinger_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-e9a3a5a454ae>\u001b[0m in \u001b[0;36mcompute_disagreement_heatmap\u001b[0;34m(list_methods, x, blackbox, metric)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_mean_disagreement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_methods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_methods\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-b676f84d0cd9>\u001b[0m in \u001b[0;36mcompute_mean_disagreement\u001b[0;34m(method1, method2, x, indices, metric)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mexp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0me1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_explanation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0me2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_explanation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-6955d37c0365>\u001b[0m in \u001b[0;36mget_explanation\u001b[0;34m(xai_config, x, targets)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mxai_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxai_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxai_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'options'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mattribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxai_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mattribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/XAIEnv/lib/python3.10/site-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/XAIEnv/lib/python3.10/site-packages/captum/attr/_core/gradient_shap.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, n_samples, stdevs, target, additional_forward_args, return_convergence_delta)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;31m# NOTE: using attribute.__wrapped__ to not log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         attributions = nt.attribute.__wrapped__(\n\u001b[0m\u001b[1;32m    270\u001b[0m             \u001b[0mnt\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/XAIEnv/lib/python3.10/site-packages/captum/attr/_core/noise_tunnel.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, nt_type, nt_samples, nt_samples_batch_size, stdevs, draw_baseline_from_distrib, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m                     \u001b[0mis_attrib_tuple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                     \u001b[0mdelta_partial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 ) = compute_partial_attribution(inputs_with_noise, kwargs_copy)\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum_attributions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/XAIEnv/lib/python3.10/site-packages/captum/attr/_core/noise_tunnel.py\u001b[0m in \u001b[0;36mcompute_partial_attribution\u001b[0;34m(inputs_with_noise_partition, kwargs_partition)\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0;31m# NOTE: using __wrapped__ such that it does not log the inner logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             attributions = attr_func.__wrapped__(  # type: ignore\n\u001b[0m\u001b[1;32m    254\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribution_method\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0minputs_with_noise_partition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/XAIEnv/lib/python3.10/site-packages/captum/attr/_core/gradient_shap.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, return_convergence_delta)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaselines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         )\n\u001b[0;32m--> 366\u001b[0;31m         grads = self.gradient_func(\n\u001b[0m\u001b[1;32m    367\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_baseline_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         )\n",
            "\u001b[0;32m/content/XAIEnv/lib/python3.10/site-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# runs forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         assert outputs[0].numel() == 1, (\n\u001b[1;32m    114\u001b[0m             \u001b[0;34m\"Target not provided when necessary, cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/XAIEnv/lib/python3.10/site-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0madditional_forward_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_additional_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     output = forward_func(\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madditional_forward_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mInceptionOutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0maux_defined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maux_logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d_2b_3x3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# N x 64 x 147 x 147\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;31m# N x 64 x 73 x 73\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d_3b_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    167\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                             return_indices=self.return_indices)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.30 GiB (GPU 0; 14.75 GiB total capacity; 13.04 GiB already allocated; 400.81 MiB free; 13.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "method_names = ['LRP', 'GradientShap', 'GuidedGradCam', 'GuidedBackprop', 'IntegratedGradients']\n",
        "test_methods = list(map(lambda name: xai_methods[name], method_names))\n",
        "heatmap = compute_disagreement_heatmap(test_methods, x.to(device), blackbox, hellinger_distance)\n",
        "heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dlw8YOFK0YL0"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(heatmap, annot=True, xticklabels=method_names, yticklabels=method_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QNwH6uaJrMH"
      },
      "source": [
        "### Kullback-Leibler divergence ([wiki](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence))\n",
        "\n",
        "Formula:\n",
        "$$D_{KL}(P||Q) = \\sum_{x \\in X} P(x) \\log{\\frac{P(x)}{Q(x)}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wocNUUXcNK0s"
      },
      "outputs": [],
      "source": [
        "def kl_divergence(x, y):\n",
        "    return np.sum(scipy.special.kl_div(x, y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1WsRPc4KGRG",
        "outputId": "835e16cf-4ed7-433e-c778-d9091de21c79"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19.975594"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kl_divergence(normalize(attribution_guidedgc.mean(axis=2)), normalize(attribution_guidedbp.mean(axis=2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCf7Oh62NVYv",
        "outputId": "f88ce582-441d-480f-c24f-fde89936ca70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "kl_divergence(normalize(attribution_guidedgc.mean(axis=2)), normalize(attribution_saliency.mean(axis=2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDwQ64ztNhrT"
      },
      "outputs": [],
      "source": [
        "a = [attribution_saliency, attribution_guidedgc, attribution_guidedbp]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjeFZNXuJAhB"
      },
      "source": [
        "# Metrics from Quantus to measure the fit between XAI methods & blackbox model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WqVYWR84VVD"
      },
      "source": [
        "## Prepare input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJxb5r6fIJ5v",
        "outputId": "c6451d80-ede6-47fb-a94b-bc77e619b5b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['GradientShap',\n",
              " 'IntegratedGradients',\n",
              " 'DeepLift',\n",
              " 'DeepLiftShap',\n",
              " 'InputXGradient',\n",
              " 'Saliency',\n",
              " 'FeatureAblation',\n",
              " 'Deconvolution',\n",
              " 'FeaturePermutation',\n",
              " 'Lime',\n",
              " 'KernelShap',\n",
              " 'LRP',\n",
              " 'Gradient',\n",
              " 'Occlusion',\n",
              " 'LayerGradCam',\n",
              " 'GuidedGradCam',\n",
              " 'LayerConductance',\n",
              " 'LayerActivation',\n",
              " 'InternalInfluence',\n",
              " 'LayerGradientXActivation',\n",
              " 'Control Var. Sobel Filter',\n",
              " 'Control Var. Constant',\n",
              " 'Control Var. Random Uniform']"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "quantus.helpers.constants.available_methods_captum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9JbwiAyHNWE"
      },
      "outputs": [],
      "source": [
        "supported_methods = {\n",
        "  \"LRP\": { },\n",
        "  \"GradientShap\": { 'n_samples': 16, 'stdevs': 0.0001, 'baselines': rand_img_dist },\n",
        "  \"IntegratedGradients\": { 'n_steps' : 50 , 'baselines': rand_img_dist },\n",
        "  'GuidedGradCam': { 'gc_layer': blackbox.Mixed_7c },\n",
        "  # Perturbation-based\n",
        "  'KernelShap': {},\n",
        "  # 'FeaturePermutation': {},\n",
        "  \"Occlusion\": { 'sliding_window_shapes': (3, 16, 16), 'strides': (3, 4, 4)}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy5m2rqekA7N"
      },
      "outputs": [],
      "source": [
        "from quantus.functions.explanation_func import explain as explain_func"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVGtR0chFhxT"
      },
      "outputs": [],
      "source": [
        "blackbox.to(cpu)\n",
        "x_batch, y_batch, s_batch = x.cpu().numpy(), y.cpu().numpy(), torch.where(transforms.Grayscale(num_output_channels=1)(mask) > 0, 1.0, 0.).cpu().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEnSpTcLkCUh"
      },
      "source": [
        "## Axiomness metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK0n7lN0gxlx"
      },
      "outputs": [],
      "source": [
        "# ATOMIC \n",
        "# Create the completeness experiment.\n",
        "completeness = quantus.Completeness(\n",
        "    perturb_baseline=\"black\",\n",
        "    perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
        ")\n",
        "\n",
        "# Call the metric instance to produce scores.\n",
        "scores = { method: completeness(model=blackbox,\n",
        "                        x_batch=x_batch,\n",
        "                        y_batch=y_batch,\n",
        "                        explain_func=explain_func,\n",
        "                        explain_func_kwargs={\"method\": method, **kwargs}) for method,kwargs in supported_methods.items()}\n",
        "scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK1Y8uJvjzPo"
      },
      "source": [
        "## Faithfulness metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08wk--wHMcWV"
      },
      "outputs": [],
      "source": [
        "infidelity = quantus.metrics.faithfulness.infidelity.Infidelity()\n",
        "results = {method: infidelity(model=blackbox, \n",
        "                                  x_batch=x_batch,\n",
        "                                  y_batch=y_batch,\n",
        "                                  a_batch=None,\n",
        "                                  device=device,\n",
        "                                  explain_func=explain_func, \n",
        "                                  explain_func_kwargs={\"method\": method, **kwargs}) for method,kwargs in supported_methods.items()}\n",
        "\n",
        "infidelity.plot(plot_func=None, results=results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "_pZ7VaiaRp8g",
        "outputId": "648e9bd1-f1c3-420d-a524-b33a2d62ae60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warnings and information:\n",
            " (1) The Region Perturbation metric is likely to be sensitive to the choice of baseline value 'perturb_baseline', the patch size for masking 'patch_size' and number of regions to evaluate 'regions_evaluation'. Also, the current implementation only works for 3-dimensional (image) data. \n",
            " (2) If attributions are normalised or their absolute values are taken it may destroy or skew information in the explanation and as a result, affect the overall evaluation outcome.\n",
            " (3) Make sure to validate the choices for hyperparameters of the metric (by calling .get_params of the metric instance).\n",
            " (4) For further information, see original publication: Samek, Wojciech, et al. 'Evaluating the visualization of what a deep neural network has learned.' IEEE transactions on neural networks and learning systems 28.11 (2016): 2660-2673.\n",
            " (5) To disable these warnings set 'disable_warnings' = True when initialising the metric.\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create the region perturbation experiment.\n",
        "region_perturb = quantus.RegionPerturbation(\n",
        "    patch_size=14,\n",
        "    regions_evaluation=10,\n",
        "    perturb_baseline=\"uniform\",  \n",
        "    normalise=True,\n",
        ")\n",
        "\n",
        "# Call the metric instance to produce scores.\n",
        "results = {method: region_perturb(model=blackbox, \n",
        "                                  x_batch=x_batch,\n",
        "                                  y_batch=y_batch,\n",
        "                                  a_batch=None,\n",
        "                                  device=device,\n",
        "                                  explain_func=explain_func, \n",
        "                                  explain_func_kwargs={\"method\": method, **kwargs}) for method,kwargs in supported_methods.items() }\n",
        "\n",
        "region_perturb.plot(plot_func=None, results=results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMYkiC3TKU5-"
      },
      "outputs": [],
      "source": [
        "# Create the pixel-flipping experiment.\n",
        "pixel_flipping = quantus.PixelFlipping(\n",
        "    features_in_step=x_batch.shape[3],\n",
        "    perturb_baseline=\"black\",\n",
        "    perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
        ")\n",
        "    \n",
        "# Call the metric instance to produce scores.\n",
        "scores = { method: pixel_flipping(model=blackbox,\n",
        "                        x_batch=x_batch,\n",
        "                        y_batch=y_batch,\n",
        "                        explain_func=explain_func,\n",
        "                        device=device,\n",
        "                        explain_func_kwargs={\"method\": method, **kwargs}) for method,kwargs in supported_methods.items()}\n",
        "pixel_flipping.plot(plot_func=None, y_batch=y_batch, scores=scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DMjjfzGTkj1"
      },
      "outputs": [],
      "source": [
        "# Create the sensitivity-n experiment.\n",
        "sensitivity_n = quantus.SensitivityN(\n",
        "    features_in_step=x_batch.shape[3],\n",
        "    n_max_percentage=0.8,\n",
        "    similarity_func=quantus.similarity_func.correlation_pearson,\n",
        "    perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
        "    perturb_baseline=\"uniform\",  \n",
        "    return_aggregate=False,\n",
        ")\n",
        "# Call the metric instance to produce scores.\n",
        "results = { method: sensitivity_n(model=blackbox, \n",
        "                        x_batch=x_batch,\n",
        "                        y_batch=y_batch,\n",
        "                        a_batch=None,\n",
        "                        device=device,\n",
        "                        explain_func=quantus.explain, \n",
        "                        explain_func_kwargs={\"method\": method, **kwargs}) for method,kwargs in supported_methods.items() }\n",
        "                        \n",
        "\n",
        "# Plot example!\n",
        "sensitivity_n.plot(plot_func=None, results=results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnR9GCIXGCdh"
      },
      "source": [
        "## Complexity Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oncnSmWHGFEZ"
      },
      "outputs": [],
      "source": [
        "complexity = quantus.Complexity()\n",
        "\n",
        "results = { method: complexity(model=blackbox,\n",
        "   x_batch=x_batch,\n",
        "   y_batch=y_batch,\n",
        "   a_batch=None,\n",
        "   explain_func=quantus.explain, \n",
        "   device=device,\n",
        "   explain_func_kwargs={\"method\": method, **kwargs}) for method,kwargs in supported_methods.items()}\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9RkmHIJiI7f"
      },
      "outputs": [],
      "source": [
        "consistancy = quantus.metrics.robustness.consistency.Consistency()\n",
        "results = { method: consistancy(model=blackbox,\n",
        "   x_batch=x_batch,\n",
        "   y_batch=y_batch,\n",
        "   a_batch=None,\n",
        "   explain_func=quantus.explain,\n",
        "   device=device,\n",
        "   explain_func_kwargs={\"method\": method, **kwargs}) for method,kwargs in supported_methods.items()}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtcnuBlhugGW"
      },
      "source": [
        "## Localisation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EQjTbxIufkB",
        "outputId": "683fbdc4-6cee-4dde-ba4d-64155cf8ccca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warnings and information:\n",
            " (1) The AUC metric is likely to be sensitive to the choice of ground truth mask i.e., the 's_batch' input as well as if absolute values 'abs' are taken of the attributions .  \n",
            " (2) If attributions are normalised or their absolute values are taken it may destroy or skew information in the explanation and as a result, affect the overall evaluation outcome.\n",
            " (3) Make sure to validate the choices for hyperparameters of the metric (by calling .get_params of the metric instance).\n",
            " (4) For further information, see original publication: Fawcett, Tom. 'An introduction to ROC analysis' Pattern Recognition Letters Vol 27, Issue 8, (2006).\n",
            " (5) To disable these warnings set 'disable_warnings' = True when initialising the metric.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'LRP': [0.5428358236416899,\n",
              "  0.5073514838237989,\n",
              "  0.5202437706409514,\n",
              "  0.5172741643107533,\n",
              "  0.49004877425327376,\n",
              "  0.5291729102339005,\n",
              "  0.5067536285363826,\n",
              "  0.4963473395548769],\n",
              " 'GradientShap': [0.4947647926556302,\n",
              "  0.49484063271596535,\n",
              "  0.5027443868822116,\n",
              "  0.47678095446087587,\n",
              "  0.491786685181539,\n",
              "  0.5057932060258262,\n",
              "  0.5060531659702809,\n",
              "  0.49628165128970037],\n",
              " 'IntegratedGradients': [0.5186582133777478,\n",
              "  0.49435887527643685,\n",
              "  0.4996525776834464,\n",
              "  0.5151369929586591,\n",
              "  0.47952897612065065,\n",
              "  0.5027627109298645,\n",
              "  0.5070789889024584,\n",
              "  0.4970337520908852],\n",
              " 'GuidedGradCam': [0.5118676632699918,\n",
              "  0.4716891308410028,\n",
              "  0.4763850713702346,\n",
              "  0.4721897734163383,\n",
              "  0.5400921943923426,\n",
              "  0.44148912592221,\n",
              "  0.5052706477382936,\n",
              "  0.5024025678255536],\n",
              " 'KernelShap': [0.46487659254139446,\n",
              "  0.4843020980169119,\n",
              "  0.4979160035507184,\n",
              "  0.4893932903269159,\n",
              "  0.4966494298731938,\n",
              "  0.5062782086710085,\n",
              "  0.5136472271851071,\n",
              "  0.5056474467917702],\n",
              " 'Occlusion': [0.5441276761015195,\n",
              "  0.4233042564462611,\n",
              "  0.7403368048083724,\n",
              "  0.6414662940403795,\n",
              "  0.6430569055983308,\n",
              "  0.5323578277575485,\n",
              "  0.7214574332867193,\n",
              "  0.5748655091599819]}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "auc = quantus.metrics.localisation.auc.AUC()\n",
        "results = { method: auc(model=blackbox,\n",
        "   x_batch=x_batch,\n",
        "   y_batch=y_batch,\n",
        "   a_batch=None,\n",
        "   s_batch=s_batch,\n",
        "   explain_func=quantus.explain,\n",
        "   device=device,\n",
        "   explain_func_kwargs={\"method\": method, **kwargs}) for method,kwargs in supported_methods.items()}\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nn8TTsLv3hJw"
      },
      "outputs": [],
      "source": [
        "# {'LRP': [0.5428358236416899,\n",
        "#   0.5073514838237989,\n",
        "#   0.5202437706409514,\n",
        "#   0.5172741643107533,\n",
        "#   0.49004877425327376,\n",
        "#   0.5291729102339005,\n",
        "#   0.5067536285363826,\n",
        "#   0.4963473395548769],\n",
        "#  'GradientShap': [0.4947647926556302,\n",
        "#   0.49484063271596535,\n",
        "#   0.5027443868822116,\n",
        "#   0.47678095446087587,\n",
        "#   0.491786685181539,\n",
        "#   0.5057932060258262,\n",
        "#   0.5060531659702809,\n",
        "#   0.49628165128970037],\n",
        "#  'IntegratedGradients': [0.5186582133777478,\n",
        "#   0.49435887527643685,\n",
        "#   0.4996525776834464,\n",
        "#   0.5151369929586591,\n",
        "#   0.47952897612065065,\n",
        "#   0.5027627109298645,\n",
        "#   0.5070789889024584,\n",
        "#   0.4970337520908852],\n",
        "#  'GuidedGradCam': [0.5118676632699918,\n",
        "#   0.4716891308410028,\n",
        "#   0.4763850713702346,\n",
        "#   0.4721897734163383,\n",
        "#   0.5400921943923426,\n",
        "#   0.44148912592221,\n",
        "#   0.5052706477382936,\n",
        "#   0.5024025678255536],\n",
        "#  'KernelShap': [0.46487659254139446,\n",
        "#   0.4843020980169119,\n",
        "#   0.4979160035507184,\n",
        "#   0.4893932903269159,\n",
        "#   0.4966494298731938,\n",
        "#   0.5062782086710085,\n",
        "#   0.5136472271851071,\n",
        "#   0.5056474467917702],\n",
        "#  'Occlusion': [0.5441276761015195,\n",
        "#   0.4233042564462611,\n",
        "#   0.7403368048083724,\n",
        "#   0.6414662940403795,\n",
        "#   0.6430569055983308,\n",
        "#   0.5323578277575485,\n",
        "#   0.7214574332867193,\n",
        "#   0.5748655091599819]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxwZL0GLKP4v"
      },
      "source": [
        "# Dashboard from OmniXAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOjH2vSVECEM"
      },
      "outputs": [],
      "source": [
        "from omnixai.preprocessing.image import Resize\n",
        "from PIL import Image\n",
        "from omnixai.data.image import Image as OmniImage\n",
        "\n",
        "def prepare_RBG_from_uri(uri):\n",
        "  imgResponse = requests.get(uri)\n",
        "  img = OmniImage(Image.open(BytesIO(imgResponse.content)).convert('RGB'))\n",
        "  return img\n",
        "\n",
        "def prepare_RBG_for_explain(uris):\n",
        "  batch = np.concatenate(\n",
        "    [Resize((224,224)).transform(prepare_RBG_from_uri(uri)).to_numpy() for uri in uris]\n",
        "  );\n",
        "  return batch\n",
        "\n",
        "x_batch = prepare_RBG_for_explain(uris);\n",
        "x_batch.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGVQEf6dfgNa"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "669FpHOOwSwX"
      },
      "outputs": [],
      "source": [
        "from omnixai.explainers.vision import VisionExplainer\n",
        "from omnixai.visualization.dashboard import Dashboard\n",
        "\n",
        "# output = torch.nn.functional.softmax(blackbox(input), dim=1)\n",
        "#     _, target = torch.topk(output[0], k=1, dim = 0)\n",
        "\n",
        "preprocess = lambda ims: torch.stack([transform(im.to_pil()) for im in ims]).to(device)\n",
        "postprocess = lambda logits: torch.nn.functional.softmax(logits, dim=1)\n",
        "\n",
        "explainer = VisionExplainer(\n",
        "    explainers=[\"lime\", \"gradcam\", \"ig\", \"ce\", \"feature_visualization\"],\n",
        "    mode=\"classification\",\n",
        "    model=blackbox,                   # An image classification model, e.g., ResNet50\n",
        "    preprocess=preprocess,         # The preprocessing function\n",
        "    postprocess=postprocess,       # The postprocessing function\n",
        "    params={\n",
        "        # Set the target layer for GradCAM\n",
        "        \"gradcam\": {\"target_layer\": blackbox.layer4[-1]},\n",
        "        # Set the objective for feature visualization\n",
        "        \"feature_visualization\": \n",
        "          {\"objectives\": [{\"layer\": blackbox.layer4[-3], \"type\": \"channel\", \"index\": list(range(6))}]},\n",
        "        \"ce\": {\"binary_search_steps\": 2, \"num_iterations\": 20},\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "img = OmniImage(data=x_batch,batched=True)\n",
        "\n",
        "# Generate explanations of GradCAM, LIME, IG and CE\n",
        "local_explanations = explainer.explain(img)\n",
        "# Generate explanations of feature visualization\n",
        "global_explanations = explainer.explain_global()\n",
        "# Launch the dashboard\n",
        "dashboard = Dashboard(\n",
        "    instances=img,\n",
        "    local_explanations=local_explanations,\n",
        "    global_explanations=global_explanations\n",
        ")\n",
        "dashboard.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3prfR5sZf1Jj",
        "gcX0anjnj3SR",
        "JjeFZNXuJAhB",
        "tK1Y8uJvjzPo",
        "gxwZL0GLKP4v"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}